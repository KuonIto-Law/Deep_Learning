{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NWVFkhv-EW2"
   },
   "source": [
    "# Lecture 7 Exercise\n",
    "\n",
    "In this exercise, I will use PyTorch to implement a basic Recurrent Neural Network (RNN) and one of its variants, Long Short-Term Memory (LSTM), to solve a text classification task.\n",
    "\n",
    "The [IMDb (Internet Movie Database)](https://huggingface.co/datasets/stanfordnlp/imdb) dataset contains movie reviews along with labels indicating whether the sentiment is positive or negative.\n",
    "\n",
    "<div style=\"text-align: center;\">Example of the Dataset</div>\n",
    "\n",
    "| Review | Label |\n",
    "|:--------:|:-------------:|\n",
    "|Where's Michael Caine when you need him? I've ...|0|\n",
    "|To experience Head you really need to understa...|1|\n",
    "\n",
    "0 = negative, 1 = positive\n",
    "\n",
    "I will input each review into the model and try binary classification of its label using an RNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-aoVICDcH2W"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    " [Exercise: Implementation and Training of RNN and Derived Models](#scrollTo=kwLF7moq_PCZ&line=1&uniqifier=1)\n",
    "1. [Loading the Dataset](#scrollTo=zEltPNkLuLz6)\n",
    "2. [Training Execution (trainer) Function Definition](#scrollTo=G-laa4YqQRji)\n",
    "3. Recurrent Neural Network (RNN) for sentiment analysis on IMDb\n",
    "\n",
    " 3.1. [Embedding Layer](#scrollTo=Urh6GUOQKBzE)  \n",
    "\n",
    " 3.2. [RNN](#scrollTo=ZNPaK9ExKBzI)  \n",
    "\n",
    " 3.3. [Classifier](#scrollTo=2O0bZWqVOVk0)\n",
    "\n",
    " 3.4. [Training](#scrollTo=emiO4f5rCklA)\n",
    "\n",
    " 3.5. [Network Implementation Using torch.nn.RNN and torch.nn.Embedding](#scrollTo=yCktWJ9N8QDN)\n",
    "\n",
    "4. Long Short-Term Memory (LSTM) for sentiment analysis on IMDb\n",
    "\n",
    " 4.1. [LSTM](#scrollTo=tsXtYkNEm1Bh)\n",
    "\n",
    " 4.2. [Classifier](#scrollTo=IfHaLvJJWHeI)\n",
    "\n",
    " 4.3. [Training](#scrollTo=qR2iKUy7yA3R)\n",
    "\n",
    " 4.4. [Network Implementation Using torch.nn.LSTM](#scrollTo=thf8W0lywagD)\n",
    "\n",
    "5. Bidirectional LSTM\n",
    "\n",
    " 5.1. [Bidirectional LSTM](#scrollTo=L9ZNn5gTP2yH)\n",
    "\n",
    " 5.2. [Training](#scrollTo=1xbAI25fQA2E)\n",
    "\n",
    "6. Supplement: [Handling Long Sequences with Gradient Clipping](#scrollTo=ExuiSiTo2k3m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "AP7Iwy3PFZ3m"
   },
   "outputs": [],
   "source": [
    "!pip install portalocker\n",
    "!pip install datasets\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import f1_score\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwLF7moq_PCZ"
   },
   "source": [
    "## Exercise: Implementation and Training of RNN and Its Variants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEltPNkLuLz6"
   },
   "source": [
    "## 1. Loading the Dataset\n",
    "\n",
    "In natural language processing, I cannot input raw text directly into the network, so I need to perform appropriate preprocessing.\n",
    "\n",
    "The general preprocessing steps (for English text) are:\n",
    "- I tokenize the text into words\n",
    "- I assign an ID to each word\n",
    "\n",
    "Through these steps, I convert the original sentence into a sequence of integers so that it can be input into the network.\n",
    "\n",
    "In this exercise, I use a library called `NLTK` to assign IDs to each word.  \n",
    "For more information, please refer to the [official documentation](https://www.nltk.org/api/nltk.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2xVBypuxc-M"
   },
   "outputs": [],
   "source": [
    "# this function for avoiding nan caused by torch.log(0)\n",
    "def torch_log(x):\n",
    "    return torch.log(torch.clamp(x, min=1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "9oN38u4fwNju"
   },
   "outputs": [],
   "source": [
    "#  dataload\n",
    "#  Even if you are prompted for a token, downloading the dataset does not require a HF (Hugging Face) token, so please click Cancel\n",
    "print(\"Loading IMDB dataset...\")\n",
    "dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "#  split the data\n",
    "train_data, valid_data = random_split(\n",
    "    dataset['train'], [20000, 5000],\n",
    "    )\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeotUWUJx9_-"
   },
   "source": [
    "I use [nltk.probability.FreqDist](https://www.nltk.org/api/nltk.probability.html#nltk.probability.FreqDist) to count the words that appear in the training sentences and build a vocabulary list (as a `FreqDist` object).\n",
    "\n",
    "I specify special tokens using the `specials` argument:\n",
    "- `<unk>`: Unknown. I use this for words that appear too infrequently to be classified.\n",
    "- `<PAD>`: I use this token to pad shorter sentences so that their lengths match longer ones.\n",
    "- `<BOS>`: Begin of sentence.\n",
    "- `<EOS>`: End of sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_Wl5lKUwNju"
   },
   "outputs": [],
   "source": [
    "#  Separate words by spaces, remove symbols like !\"#$%&, convert everything to lowercase, etc.\n",
    "def tokenize(text):\n",
    "    #  1. Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    #  2. Remove punctuation (string.punctuation)\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "    #  3. Tokenize (split into words)\n",
    "    tokens = text.split()\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "wTwwv3qJxrXG"
   },
   "outputs": [],
   "source": [
    "#  Create a FreqDist object to record word frequencies\n",
    "counter = FreqDist()\n",
    "for i in range(len(train_data)):\n",
    "    processed = tokenize(train_data[i][\"text\"])\n",
    "    #  Add the tokenized word list to FreqDist and update frequencies\n",
    "    counter.update(processed)\n",
    "\n",
    "print(f\"Vocabulary size: {len(counter)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtZDWtT4FYBh"
   },
   "outputs": [],
   "source": [
    "#  Set <unk> as the default, and replace words that appear fewer than min_freq times with <unk>\n",
    "#  Apply min_freq and specials\n",
    "min_freq = 25\n",
    "specials = ['<unk>', '<PAD>', '<BOS>', '<EOS>']\n",
    "\n",
    "vocab = specials + [word for word, freq in counter.items() if freq >= min_freq]\n",
    "vocab_dict = {word: i for i, word in enumerate(vocab)}\n",
    "word_num = len(vocab_dict)\n",
    "\n",
    "print(f\"Number of unique words: {word_num}\")\n",
    "print(list(vocab_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eXWV-W9fsJ2"
   },
   "source": [
    "Call `text_transform()` from within `collate_batch()` to convert a list of words into a list of indices based on the vocabulary dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "waztS-jcwNjv"
   },
   "outputs": [],
   "source": [
    "def text_transform(_text, max_length=256):\n",
    "    #  If a token is not in vocab_dict, assign 0 = <unk>. Subtract 2 to account for <BOS> and <EOS> tokens.\n",
    "    text = [vocab_dict.get(token, 0) for token in tokenize(_text)][:max_length - 2]\n",
    "    text = [vocab_dict['<BOS>']] + text + [vocab_dict['<EOS>']]\n",
    "    return text, len(text)\n",
    "\n",
    "def collate_batch(batch):\n",
    "   label_list, text_list, len_seq_list = [], [], []\n",
    "\n",
    "   for data_point  in list(batch):\n",
    "      _text = data_point.get('text')\n",
    "      _label = data_point.get('label')\n",
    "      label_list.append(_label)\n",
    "\n",
    "      processed_text, len_seq = text_transform(_text)\n",
    "      text_list.append(torch.tensor(processed_text))\n",
    "      len_seq_list.append(len_seq)\n",
    "\n",
    "   return torch.tensor(label_list), pad_sequence(text_list, padding_value=1).T, torch.tensor(len_seq_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4wrvRPx_k4H"
   },
   "source": [
    "By passing the `collate_batch()` function defined above to the `DataLoader`, I can apply that processing to each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zNihuaPSuNl"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "   list(train_data),\n",
    "   batch_size=batch_size,\n",
    "   shuffle=True,\n",
    "   collate_fn=collate_batch\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "   list(valid_data),\n",
    "   batch_size=batch_size,\n",
    "   shuffle=False,\n",
    "   collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-laa4YqQRji"
   },
   "source": [
    "## 2.Training Execution(trainer)Function Definition\n",
    "\n",
    "Since the training loop will be the same for all models defined later, I will implement it here as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmcVzxAvQbdJ"
   },
   "outputs": [],
   "source": [
    "# NOTE: dataloader is in the global scope\n",
    "def train(net, optimizer, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        losses_train = []\n",
    "        losses_valid = []\n",
    "\n",
    "        net.train()\n",
    "        n_train = 0\n",
    "        acc_train = 0\n",
    "        for label, line, len_seq in train_dataloader:\n",
    "            net.zero_grad()  # Initialize gradients\n",
    "\n",
    "            t = label.to(device)  # Move tensor to GPU\n",
    "            x = line.to(device)   # (batch, time)\n",
    "            len_seq.to(device)\n",
    "\n",
    "            h = net(x, torch.max(len_seq), len_seq)\n",
    "            y = torch.sigmoid(h).squeeze()\n",
    "\n",
    "            loss = -torch.mean(t * torch_log(y) + (1 - t) * torch_log(1 - y)) \n",
    "\n",
    "            loss.backward()  # Backpropagation\n",
    "\n",
    "            optimizer.step()  # Update parameters\n",
    "\n",
    "            losses_train.append(loss.tolist())\n",
    "\n",
    "            n_train += t.size()[0]\n",
    "\n",
    "        # Validation\n",
    "        t_valid = []\n",
    "        y_pred = []\n",
    "        net.eval()\n",
    "        for label, line, len_seq in valid_dataloader:\n",
    "\n",
    "            t = label.to(device)  # Move tensor to GPU\n",
    "            x = line.to(device)\n",
    "            len_seq.to(device)\n",
    "\n",
    "            h = net(x, torch.max(len_seq), len_seq)\n",
    "            y = torch.sigmoid(h).squeeze()\n",
    "\n",
    "            loss = -torch.mean(t * torch_log(y) + (1 - t) * torch_log(1 - y))  \n",
    "\n",
    "            pred = y.round().squeeze()  # Predict positive label for values >= 0.5\n",
    "\n",
    "            t_valid.extend(t.tolist())\n",
    "            y_pred.extend(pred.tolist())\n",
    "\n",
    "            losses_valid.append(loss.tolist())\n",
    "\n",
    "        print('EPOCH: {}, Train Loss: {:.3f}, Valid Loss: {:.3f}, Validation F1: {:.3f}'.format(\n",
    "            epoch,\n",
    "            np.mean(losses_train),\n",
    "            np.mean(losses_valid),\n",
    "            f1_score(t_valid, y_pred, average='macro')\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5oyIOujKBy0"
   },
   "source": [
    "## 3.Recurrent Neural Network (RNN) for sentiment analysis on IMDb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Urh6GUOQKBzE"
   },
   "source": [
    "### 3.1. Embedding Layer\n",
    "\n",
    "In the `Embedding` layer, I convert words from discrete IDs into continuous, high-dimensional vectors (called embeddings).\n",
    "\n",
    "In the `Embedding` class below, the input $\\boldsymbol{x}$ is a matrix where each row contains a sequence of word IDs for a sentence. The weight matrix $\\boldsymbol{V}$ is a matrix where each row corresponds to the vector representation of a word ID.\n",
    "\n",
    "The dimensions of each matrix are as follows:\n",
    "\n",
    "- $\\boldsymbol{x}$: (mini-batch size) × (maximum sequence length in the batch)  \n",
    "- $\\boldsymbol{V}$: (vocabulary size) × (embedding dimension)\n",
    "\n",
    "By using $\\boldsymbol{V}$ to look up the vector for each word ID in $\\boldsymbol{x}$, I convert each word into its corresponding embedding vector.\n",
    "\n",
    "As a result, the output tensor has the shape:  \n",
    "(mini-batch size) × (maximum sequence length in the batch) × (embedding dimension)\n",
    "\n",
    "\n",
    "![embedding](data:image/png;base64,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)\n",
    "\n",
    "Let $m$: embedding dimension, and $n$: vocabulary size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsrziOUkFX07"
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_matrix = nn.Parameter(torch.randn((vocab_size, emb_dim),  #  Generates random numbers from a Gaussian (normal) distribution\n",
    "                                                        dtype=torch.float))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.embedding(x, self.embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNPaK9ExKBzI"
   },
   "source": [
    "### 3.2. RNN\n",
    "\n",
    "In the `RNN` class, I process the input obtained by converting each word into a vector using the Embedding layer. Here, the input $\\boldsymbol{x}$ has the following dimensions:\n",
    "\n",
    "- $\\boldsymbol{x}$: (mini-batch size) × (maximum sequence length in the batch) × (embedding dimension)\n",
    "\n",
    "I define the `RNN` class using `nn.Module`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qq01kXOFw3hD"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        glorot = 6 / (in_dim + hid_dim * 2)\n",
    "        self.W = nn.Parameter(torch.tensor(np.random.uniform(\n",
    "                        low=-np.sqrt(glorot),\n",
    "                        high=np.sqrt(glorot),\n",
    "                        size=(in_dim + hid_dim, hid_dim)\n",
    "                    ).astype('float32')))\n",
    "        self.b = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
    "\n",
    "    def function(self, h, x):\n",
    "        return torch.tanh(torch.matmul(torch.cat([h, x], dim=1), self.W) + self.b)\n",
    "\n",
    "    def forward(self, x, len_seq_max=0, init_state=None):\n",
    "        x = x.transpose(0, 1)  # Transpose dimensions to (sequence, batch) for batch processing\n",
    "        state = init_state\n",
    "\n",
    "        if init_state is None:  # Initialize with zeros if no initial state is provided\n",
    "            state = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
    "\n",
    "        size = list(state.unsqueeze(0).size())\n",
    "        size[0] = 0\n",
    "        output = torch.empty(size, dtype=torch.float).to(x.device)  # Create an empty tensor to accumulate outputs\n",
    "\n",
    "        if len_seq_max == 0:\n",
    "            len_seq_max = x.size(0)\n",
    "        for i in range(len_seq_max):\n",
    "            state = self.function(state, x[i])\n",
    "            output = torch.cat([output, state.unsqueeze(0)])  # Append to output sequence\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O0bZWqVOVk0"
   },
   "source": [
    "### 3.3. Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpDGYK_rEcVS"
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "class SequenceTaggingNet(nn.Module):\n",
    "    def __init__(self, word_num, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.emb = Embedding(word_num, emb_dim)\n",
    "        self.rnn = RNN(emb_dim, hid_dim)\n",
    "        self.linear = nn.Linear(hid_dim, 1)\n",
    "\n",
    "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
    "        h = self.emb(x)  \n",
    "        h = self.rnn(h, len_seq_max, init_state)\n",
    "        if len_seq is not None:\n",
    "            # Since we need the output at the end of each sequence, aggregate using len_seq\n",
    "            h = h[len_seq - 1, list(range(len(x))), :]\n",
    "        else:\n",
    "            h = h[-1]\n",
    "        y = self.linear(h)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emiO4f5rCklA"
   },
   "source": [
    "### 3.4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "NF1oS8scU160"
   },
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "hid_dim = 50\n",
    "n_epochs = 10\n",
    "device = 'cuda'\n",
    "\n",
    "net = SequenceTaggingNet(word_num, emb_dim, hid_dim)\n",
    "net.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "train(net, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCktWJ9N8QDN"
   },
   "source": [
    "### 3.5. Network Implementation Using `torch.nn.RNN` and `torch.nn.Embedding`\n",
    "\n",
    "Just like how `torch.nn.Conv2d` allows easy implementation of CNN layers, `torch.nn.RNN` makes it simple to implement RNN layers.\n",
    "\n",
    "`torch.nn.RNN` takes a sequence input $x$ and an initial hidden state $h_0$ as arguments, and returns the output sequence $y$ and the final hidden state $h$ (`y, h = self.RNN(x, h_0)`).\n",
    "\n",
    "However, one slightly tricky aspect is that `nn.RNN` expects the input sequence data in the shape [sequence length, batch size, feature dimension] by default. On the other hand, data provided by the DataLoader is typically in the shape [batch size, sequence length, feature dimension], which is often considered more intuitive. \n",
    "\n",
    "To handle this, `torch.nn.RNN` accepts a `batch_first` argument. By setting `batch_first=True`, the input sequence can be passed in the [batch size, sequence length, feature dimension] format.\n",
    "\n",
    "Note that when `batch_first=True`, the output will also follow that format. If you need to extract outputs in the [sequence length, batch size, feature dimension] format (e.g., to align with `len_seq`), you can use `transpose` accordingly.\n",
    "\n",
    "Additionally, `torch.nn.RNN` has a `num_layers` argument that specifies the number of stacked RNN layers. While stacking multiple layers is possible, we use a single layer here for consistency with the implementation in Task 2.\n",
    "\n",
    "Similarly, `torch.nn.Embedding` makes it easy to implement the embedding layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xou_yoP8Uxrs"
   },
   "outputs": [],
   "source": [
    "# nn.RNN\n",
    "class SequenceTaggingNet2(nn.Module):\n",
    "    def __init__(self, word_num, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(word_num, emb_dim)  # Use nn.Embedding\n",
    "        self.rnn = nn.RNN(emb_dim, hid_dim, 1, batch_first=True)  # Use nn.RNN\n",
    "        self.linear = nn.Linear(hid_dim, 1)\n",
    "\n",
    "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
    "        h = self.emb(x)\n",
    "        if len_seq_max > 0:\n",
    "            h, _ = self.rnn(h[:, 0:len_seq_max, :], init_state)\n",
    "        else:\n",
    "            h, _ = self.rnn(h, init_state)\n",
    "        h = h.transpose(0, 1)\n",
    "        if len_seq is not None:\n",
    "            # Since we need the output at the end of each sequence, aggregate using len_seq\n",
    "            h = h[len_seq - 1, list(range(len(x))), :]\n",
    "        else:\n",
    "            h = h[-1]\n",
    "\n",
    "        y = self.linear(h)\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlab8ft3U0Fq"
   },
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "hid_dim = 50\n",
    "n_epochs = 10\n",
    "device = 'cuda'\n",
    "\n",
    "net = SequenceTaggingNet2(word_num, emb_dim, hid_dim)\n",
    "net.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "train(net, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzcDxaEvmu_g"
   },
   "source": [
    "## 4.Long short-term memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsXtYkNEm1Bh"
   },
   "source": [
    "### 4.1. LSTM\n",
    "\n",
    "The LSTM implementation follows the equations below. (Here, $\\odot$ denotes element-wise multiplication):\n",
    "\n",
    "- Input gate: $\\hspace{20mm}\\boldsymbol{i}_t = \\sigma \\left(\\boldsymbol{W}_i \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_i\\right)$  \n",
    "- Forget gate: $\\hspace{20mm}\\boldsymbol{f}_t = \\sigma \\left(\\boldsymbol{W}_f \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_f\\right)$  \n",
    "- Output gate: $\\hspace{20mm}\\boldsymbol{o}_t = \\sigma \\left(\\boldsymbol{W}_o \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_o\\right)$  \n",
    "- Cell state: $\\hspace{20mm}\\boldsymbol{c}_t = \\boldsymbol{f}_t \\odot \\boldsymbol{c}_{t-1} + \\boldsymbol{i}_t \\odot \\tanh \\left(\\boldsymbol{W}_c \\left[\\begin{array}{c} \\boldsymbol{x}_t \\\\ \\boldsymbol{h}_{t-1} \\end{array}\\right] + \\boldsymbol{b}_c\\right)$  \n",
    "- Hidden state: $\\hspace{20mm}\\boldsymbol{h}_t = \\boldsymbol{o}_t \\odot \\tanh \\left(\\boldsymbol{c}_t \\right)$\n",
    "\n",
    "Note that in a simple RNN, each step returns only the hidden state ($\\boldsymbol{h}_t$), whereas in an LSTM, both the cell state and the hidden state ($\\boldsymbol{c}_t$, $\\boldsymbol{h}_t$) are returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Zp__4EDBoJ3"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        glorot = 6 / (in_dim + hid_dim * 2)\n",
    "\n",
    "        self.W_i = nn.Parameter(torch.tensor(np.random.uniform(\n",
    "            low=-np.sqrt(glorot),\n",
    "            high=np.sqrt(glorot),\n",
    "            size=(in_dim + hid_dim, hid_dim)\n",
    "        ).astype('float32')))\n",
    "        self.b_i = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
    "\n",
    "        self.W_f = nn.Parameter(torch.tensor(np.random.uniform(\n",
    "            low=-np.sqrt(glorot),\n",
    "            high=np.sqrt(glorot),\n",
    "            size=(in_dim + hid_dim, hid_dim)\n",
    "        ).astype('float32')))\n",
    "        self.b_f = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
    "\n",
    "        self.W_o = nn.Parameter(torch.tensor(np.random.uniform(\n",
    "            low=-np.sqrt(glorot),\n",
    "            high=np.sqrt(glorot),\n",
    "            size=(in_dim + hid_dim, hid_dim)\n",
    "        ).astype('float32')))\n",
    "        self.b_o = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
    "\n",
    "        self.W_c = nn.Parameter(torch.tensor(np.random.uniform(\n",
    "            low=-np.sqrt(glorot),\n",
    "            high=np.sqrt(glorot),\n",
    "            size=(in_dim + hid_dim, hid_dim)\n",
    "        ).astype('float32')))\n",
    "        self.b_c = nn.Parameter(torch.tensor(np.zeros([hid_dim]).astype('float32')))\n",
    "\n",
    "    def function(self, state_c, state_h, x):\n",
    "        i = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_i) + self.b_i)  # Input gate\n",
    "        f = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_f) + self.b_f)  # Forget gate\n",
    "        o = torch.sigmoid(torch.matmul(torch.cat([state_h, x], dim=1), self.W_o) + self.b_o)  # Output gate\n",
    "        c = f * state_c + i * torch.tanh(torch.matmul(torch.cat([state_h, x], dim=1), self.W_c) + self.b_c)  # Cell state\n",
    "        h = o * torch.tanh(c)  # Hidden state\n",
    "        return c, h\n",
    "\n",
    "    def forward(self, x, len_seq_max=0, init_state_c=None, init_state_h=None):\n",
    "        x = x.transpose(0, 1)  # Transpose dimensions to (sequence, batch) for batch processing\n",
    "        state_c = init_state_c\n",
    "        state_h = init_state_h\n",
    "        if init_state_c is None:  # Initialize with zeros if no initial cell state is provided\n",
    "            state_c = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
    "        if init_state_h is None:  # Initialize with zeros if no initial hidden state is provided\n",
    "            state_h = torch.zeros((x[0].size()[0], self.hid_dim)).to(x.device)\n",
    "\n",
    "        size = list(state_h.unsqueeze(0).size())\n",
    "        size[0] = 0\n",
    "        output = torch.empty(size, dtype=torch.float).to(x.device)  # Create an empty tensor to accumulate outputs\n",
    "\n",
    "        if len_seq_max == 0:\n",
    "            len_seq_max = x.size(0)\n",
    "        for i in range(len_seq_max):\n",
    "            state_c, state_h = self.function(state_c, state_h, x[i])\n",
    "            output = torch.cat([output, state_h.unsqueeze(0)])  # Append hidden state to output sequence\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfHaLvJJWHeI"
   },
   "source": [
    "### 4.2. Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mU-z8OtZu_cO"
   },
   "outputs": [],
   "source": [
    "#  LSTM\n",
    "class SequenceTaggingNet3(nn.Module):\n",
    "    def __init__(self, word_num, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.emb = Embedding(word_num, emb_dim)\n",
    "        self.lstm = LSTM(emb_dim, hid_dim)\n",
    "        self.linear = nn.Linear(hid_dim, 1)\n",
    "\n",
    "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
    "        h = self.emb(x)  \n",
    "        h = self.lstm(h, len_seq_max, init_state)  \n",
    "        if len_seq is not None:\n",
    "            # need to take the output at the end of the sequence and aggregate based on len_seq\n",
    "            h = h[len_seq - 1, list(range(len(x))), :]\n",
    "        else:\n",
    "            h = h[-1]\n",
    "\n",
    "        y = self.linear(h) \n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qR2iKUy7yA3R"
   },
   "source": [
    "### 4.3. Training\n",
    "\n",
    "Compare the performance of RNNs and LSTMs on the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAyD__D8vLvi"
   },
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "hid_dim = 50\n",
    "n_epochs = 5\n",
    "device = 'cuda'\n",
    "\n",
    "net = SequenceTaggingNet3(word_num, emb_dim, hid_dim)\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "train(net, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thf8W0lywagD"
   },
   "source": [
    "### 4.4. `nn.LSTM`Network Implementation Using\n",
    "\n",
    "LSTM can be implemented using `nn.LSTM` as well as RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXqI364xviGx"
   },
   "outputs": [],
   "source": [
    "#  nn.LSTM\n",
    "class SequenceTaggingNet4(nn.Module):\n",
    "    def __init__(self, word_num, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(word_num, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, 1, batch_first=True)  #  nn.LSTM\n",
    "        self.linear = nn.Linear(hid_dim, 1)\n",
    "\n",
    "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
    "        h = self.emb(x)\n",
    "        if len_seq_max > 0:\n",
    "            h, _ = self.lstm(h[:, 0:len_seq_max, :], init_state)\n",
    "        else:\n",
    "            h, _ = self.lstm(h, init_state)\n",
    "        h = h.transpose(0, 1)\n",
    "        if len_seq is not None:\n",
    "            h = h[len_seq - 1, list(range(len(x))), :]\n",
    "        else:\n",
    "            h = h[-1]\n",
    "        y = self.linear(h)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6D8KzZcw0pv"
   },
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "hid_dim = 50\n",
    "n_epochs = 10\n",
    "device = 'cuda'\n",
    "\n",
    "net = SequenceTaggingNet4(word_num, emb_dim, hid_dim)\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "train(net, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj0XA0PQP0gG"
   },
   "source": [
    "## 5.BidirectionalLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9ZNn5gTP2yH"
   },
   "source": [
    "### 5.1. Bidirectional LSTM\n",
    "\n",
    "In a Bidirectional LSTM, I prepare two separate LSTM networks: one that processes the sequence in the forward direction (`self.forward_lstm`), and another that processes it in the reverse direction (`self.backward_lstm`).  \n",
    "The outputs from both directions are then concatenated and passed to a fully connected layer.  \n",
    "While this increases the number of parameters, it allows the model to make predictions that take into account both past and future context.\n",
    "\n",
    "Although this can be implemented simply by setting `bidirectional=True` in [nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html), I implement it manually here for the sake of understanding how it works.\n",
    "\n",
    "- In this implementation, the `BidirectionalLSTM` class includes the classifier functionality that has previously been implemented in the `SequenceTaggingNet`. (Either approach is fine in practice.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XefPHJEyP5vY"
   },
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "    def __init__(self, word_num, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        # Prepare LSTMs for forward and backward directions\n",
    "        self.emb = nn.Embedding(word_num, emb_dim)\n",
    "        self.forward_lstm = nn.LSTM(emb_dim, hid_dim, 1, batch_first=True)\n",
    "        self.backward_lstm = nn.LSTM(emb_dim, hid_dim, 1, batch_first=True)\n",
    "        self.linear = nn.Linear(hid_dim * 2, 1)  # Output from forward and backward LSTMs are concatenated\n",
    "\n",
    "    def forward(self, x, len_seq_max=0, len_seq=None, init_state=None):\n",
    "        h = self.emb(x)  # (batch_size, seq_length, emb_dim)\n",
    "\n",
    "        # Reverse the sequence for the backward LSTM\n",
    "        if len_seq_max > 0:\n",
    "            h1, _ = self.forward_lstm(h[:, 0:len_seq_max, :], init_state)\n",
    "            h2, _ = self.backward_lstm(torch.flip(h[:, 0:len_seq_max, :], dims=[1]), init_state)\n",
    "        else:\n",
    "            h1, _ = self.forward_lstm(h, init_state)  # (batch_size, seq_length, hid_dim)\n",
    "            h2, _ = self.backward_lstm(torch.flip(h, dims=[1]), init_state)  # (batch_size, seq_length, hid_dim)\n",
    "\n",
    "        # Flip the output of the backward LSTM back to the original order\n",
    "        h2 = torch.flip(h2, dims=[1])\n",
    "\n",
    "        # Concatenate the outputs of the forward and backward LSTMs\n",
    "        h = torch.cat([h1, h2], dim=2).transpose(0, 1)\n",
    "\n",
    "        if len_seq is not None:\n",
    "            h = h[len_seq - 1, list(range(len(x))), :]\n",
    "        else:\n",
    "            h = h[-1]\n",
    "\n",
    "        y = self.linear(h)\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xbAI25fQA2E"
   },
   "source": [
    "### 5.2. Training\n",
    "\n",
    "Bidirectional LSTM performs the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UJx334FQBbK"
   },
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "hid_dim = 50\n",
    "n_epochs = 10\n",
    "device = 'cuda'\n",
    "\n",
    "net = BidirectionalLSTM(word_num, emb_dim, hid_dim)\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "train(net, optimizer, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExuiSiTo2k3m"
   },
   "source": [
    "## 6. Supplement: Handling Long Sequences with Gradient Clipping\n",
    "\n",
    "While LSTMs are generally well-suited for training on long sequences, here I introduce **Gradient Clipping** as a technique for handling long sequences in standard RNNs.\n",
    "\n",
    "In RNNs, the backpropagation algorithm is specifically referred to as **Back Propagation Through Time (BPTT)**, where gradients are multiplied not only across layers but also across time steps.\n",
    "\n",
    "As a result, gradients are prone to becoming excessively large or small compared to standard backpropagation.\n",
    "\n",
    "This phenomenon is known as the **exploding (or vanishing) gradient problem**. Exploding gradients, in particular, can destabilize training and make convergence difficult.\n",
    "\n",
    "![Clipping](../figures/Clipping.png)  \n",
    "Source: Ian Goodfellow et al., *Deep Learning*, MIT Press, 2016 (http://www.deeplearningbook.org/)\n",
    "\n",
    "To address this, **Gradient Clipping** deliberately limits the magnitude of the gradients.\n",
    "\n",
    "You can apply gradient clipping in PyTorch using the following function:\n",
    "\n",
    "```python\n",
    "torch.nn.utils.clip_grad_norm_(parameters, max_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lpu3TlsbxAuK"
   },
   "outputs": [],
   "source": [
    "def train_gradient_clipping(net, optimizer, n_epochs,\n",
    "):\n",
    "    for epoch in range(n_epochs):\n",
    "        losses_train = []\n",
    "        losses_valid = []\n",
    "\n",
    "        net.train()\n",
    "        n_train = 0\n",
    "        acc_train = 0\n",
    "        for label, line, len_seq in train_dataloader:\n",
    "\n",
    "            net.zero_grad()\n",
    "\n",
    "            t = label.to(device)  #  Move tensor to GPU\n",
    "            x = line.to(device) #  ( batch, time )\n",
    "            len_seq.to(device)\n",
    "\n",
    "            h = net(x, torch.max(len_seq), len_seq)\n",
    "            y = torch.sigmoid(h).squeeze()\n",
    "\n",
    "            loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            #  Clipping the slope with an absolute value of 1.0\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            losses_train.append(loss.tolist())\n",
    "\n",
    "            n_train += t.size()[0]\n",
    "\n",
    "        t_valid = []\n",
    "        y_pred = []\n",
    "        net.eval()\n",
    "        for label, line, len_seq in valid_dataloader:\n",
    "\n",
    "            t = label.to(device)  #  Move tensor to GPU\n",
    "            x = line.to(device) #  ( batch, time )\n",
    "            len_seq.to(device)\n",
    "\n",
    "            h = net(x, torch.max(len_seq), len_seq)\n",
    "            y = torch.sigmoid(h).squeeze()\n",
    "\n",
    "            loss = -torch.mean(t*torch_log(y) + (1 - t)*torch_log(1 - y))\n",
    "\n",
    "            pred = y.round().squeeze()\n",
    "\n",
    "            t_valid.extend(t.tolist())\n",
    "            y_pred.extend(pred.tolist())\n",
    "\n",
    "            losses_valid.append(loss.tolist())\n",
    "\n",
    "        print('EPOCH: {}, Train Loss: {:.3f}, Valid Loss: {:.3f}, Validation F1: {:.3f}'.format(\n",
    "            epoch,\n",
    "            np.mean(losses_train),\n",
    "            np.mean(losses_valid),\n",
    "            f1_score(t_valid, y_pred, average='macro')\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MbcEGef5okD"
   },
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "hid_dim = 50\n",
    "n_epochs = 10\n",
    "device = 'cuda'\n",
    "\n",
    "net = SequenceTaggingNet2(word_num, emb_dim, hid_dim)\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "train_gradient_clipping(net, optimizer, n_epochs)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4928584a19934792772f8bb8909943c28c334459e9e815fcc970144b80af4840"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
